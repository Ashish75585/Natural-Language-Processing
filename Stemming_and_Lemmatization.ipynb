{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5aEjNy9EoeJ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Note:` Spacy don't have `stemming`."
      ],
      "metadata": {
        "id": "LQDaP-_XG4PK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming\n"
      ],
      "metadata": {
        "id": "LM-jn9bcILfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "RPuIeG17GxqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "  print(word, \" | \", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyqgaPWQHSnB",
        "outputId": "5f946a7b-7784-46e4-ee96-721a15b2e474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat\n",
            "eats  |  eat\n",
            "eat  |  eat\n",
            "ate  |  ate\n",
            "adjustable  |  adjust\n",
            "rafting  |  raft\n",
            "ability  |  abil\n",
            "meeting  |  meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization"
      ],
      "metadata": {
        "id": "U2HW5VrtIN95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token,  \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lkvzzQfHpj_",
        "outputId": "2ec2db0e-b13b-48e4-b4e3-b5e2dc497965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat\n",
            "eats  |  eat\n",
            "eat  |  eat\n",
            "ate  |  eat\n",
            "adjustable  |  adjustable\n",
            "rafting  |  raft\n",
            "ability  |  ability\n",
            "meeting  |  meeting\n",
            "better  |  well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0yzXet3Ixq7",
        "outputId": "d92fae06-c8c2-454f-ca78-f174cddd7ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`attribute_ruler` assigns attributes to `tokens`, which we can modify."
      ],
      "metadata": {
        "id": "CvS5Al3LJ19n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstration of \"attribute_ruler\"\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "\n",
        "# in above sentence, \"bro\" and \"brah\" is not a proper english words. But their meaning is \"brother\". So \"lemma_\" won't be able to recognize it.\n",
        "\n",
        "#e.g.\n",
        "for token in doc:\n",
        "  print(token.text, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ID0JmRoJwyn",
        "outputId": "16179d75-4004-4102-aa64-1a4f92f54c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro  |  bro\n",
            ",  |  ,\n",
            "you  |  you\n",
            "wanna  |  wanna\n",
            "go  |  go\n",
            "?  |  ?\n",
            "Brah  |  Brah\n",
            ",  |  ,\n",
            "do  |  do\n",
            "n't  |  not\n",
            "say  |  say\n",
            "no  |  no\n",
            "!  |  !\n",
            "I  |  I\n",
            "am  |  be\n",
            "exhausted  |  exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but we can modify the tokens with help of \"attribute_ruler\"\n",
        "\n",
        "ar = nlp.get_pipe(\"attribute_ruler\")\n",
        "\n",
        "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\":\"Brah\"}]], {\"LEMMA\":\"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gl8TGN-K1R9",
        "outputId": "c8141597-6d8a-4341-9a72-d324d216f97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro  |  Brother\n",
            ",  |  ,\n",
            "you  |  you\n",
            "wanna  |  wanna\n",
            "go  |  go\n",
            "?  |  ?\n",
            "Brah  |  Brother\n",
            ",  |  ,\n",
            "do  |  do\n",
            "n't  |  not\n",
            "say  |  say\n",
            "no  |  no\n",
            "!  |  !\n",
            "I  |  I\n",
            "am  |  be\n",
            "exhausted  |  exhaust\n"
          ]
        }
      ]
    }
  ]
}